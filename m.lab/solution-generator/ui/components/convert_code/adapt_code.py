from contextlib import redirect_stdout
from io import StringIO
import os
import re
import shutil
import json
import streamlit as st
from engine.chatgpt import chatgpt_query
# from engine.adapt_data.adapt_data_to_code import DataAdapt
from engine.adapt_data.graph_runner import GraphRunner
import pandas as pd
from rich.tree import Tree
from rich.console import Console
from ui.components.convert_code.upload_data import UploadData

from path_list import *

class AdaptCode:
    def __init__(self, path):
        self.data_path = path['data']
        self.py_path = path['source_py']
        self.metadata_path = path['metadata']
        self.data_path = path['data']

        self._initialize_session_state()

    def _initialize_session_state(self):
        default_states = {
            "max_iterations_data": 10,
            'log_data': "",
            'placeholder_data': None,
            'is_btn_clicked_data': False,
            'data_adapt': None,
        }

        for key, value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = value

    def check_condition(self):
        with st.container(border=True):
            st.caption('ì‹¤í–‰ ì¡°ê±´')

            # Check if 'train' and 'inference' folders exist in data_path
            train_path = os.path.join(self.data_path, 'train')
            inference_path = os.path.join(self.data_path, 'inference')

            train_exists = os.path.isdir(train_path) and len(os.listdir(train_path)) > 0
            inference_exists = os.path.isdir(inference_path) and len(os.listdir(inference_path)) > 0
            data_checked = train_exists and inference_exists

            # Check if 'requirements.txt' and at least one .py file exist in py_path
            requirements_exists = os.path.isfile(os.path.join(self.py_path, 'requirements.txt'))
            py_files_exist = any(file.endswith('.py') for file in os.listdir(self.py_path) if os.path.isfile(os.path.join(self.py_path, file)))
            source_code_checked = requirements_exists and py_files_exist

            col1, col2 = st.columns(2)
            with col1:
                st.checkbox("ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ëŠ”ê°€?", value=data_checked, disabled=True)
            with col2:
                st.checkbox("ì†ŒìŠ¤ì½”ë“œê°€ ì¡´ì¬í•˜ëŠ”ê°€?", value=source_code_checked, disabled=True)

        return data_checked and source_code_checked
        
    def show_adapt_code_info(self):
        st.caption('AI Agentë¥¼ í™œìš©í•´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì†ŒìŠ¤ ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.   \n   ì‹¤íŒ¨í•œë‹¤ë©´ í˜„ì¬ íƒ­ì˜ `Edit Code`ì—ì„œ ìˆ˜ì •í•˜ê±°ë‚˜ `Get AI Source`ì— ëŒì•„ê°€ ìƒˆë¡œìš´ ì†ŒìŠ¤ ì½”ë“œë¥¼ ë°›ì•„ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
        with st.expander('ğŸ’¥ ì™œ ì½”ë“œ ìˆ˜ì • ê³¼ì •ì„ ë‘ ë²ˆ(Adapt Code for Dataset, Generate AI Solution)ì´ë‚˜ ì§„í–‰í•˜ë‚˜ìš”?'):
            st.markdown("""
                - ê³µí†µì : ë‘ ì½”ë“œì˜ ìˆ˜ì • ëª¨ë‘ AI Agentë¥¼ í™œìš©í•´ ì½”ë“œë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.
                - ì°¨ì´ì : 
                    - `Adapt Code for Dataset`ì—ì„œ ì§„í–‰í•˜ëŠ” ìˆ˜ì •: ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹ê³¼ kaggleì—ì„œ ë‹¤ìš´ë¡œë“œ ë°›ì€ ë…¸íŠ¸ë¶ì˜ ì½”ë“œê°€ í˜¸í™˜ì´ ì•ˆë  ìˆ˜ ìˆì–´, <span style="color:red">ë°ì´í„°ì…‹ì— ë§ê²Œ</span> ì½”ë“œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
                    - `Generate AI Solution`ì—ì„œ ì§„í–‰í•˜ëŠ” ìˆ˜ì •: ì‹¤í–‰ë˜ëŠ” ì†ŒìŠ¤ ì½”ë“œë¥¼ <span style="color:red">AI Solutionì˜ í˜•ì‹ì— ì í•©í•œ</span> ì½”ë“œë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
            """, unsafe_allow_html=True)

    def print_directory_tree(self, startpath, max_files=5):
        """
        Given a startpath, print a visual tree with a limited number of files.
        """
        tree = Tree(startpath)

        def add_branch(tree, path, max_files=5):
            dirs = []
            files = []
            for item in os.listdir(path):
                full_path = os.path.join(path, item)
                if os.path.isdir(full_path):
                    dirs.append(item)
                elif os.path.isfile(full_path):
                    files.append(item)

            for dir_ in dirs:
                branch = tree.add(f"ğŸ“ {dir_}")
                add_branch(branch, os.path.join(path, dir_), max_files)

            for f in files[:max_files]:  # only show up to max_files files
                tree.add(f"ğŸ“„ {f}")

            if len(files) > max_files:  # add ellipsis for remaining files
                tree.add(f"...and {len(files) - max_files} more")

        add_branch(tree, startpath)

        console = Console()
        output = StringIO()
        with redirect_stdout(output):
            console.print(tree)
        return output.getvalue()
    
    def create_solution(self):
        st.write('#### Adapt Code')
        st.caption('ì†ŒìŠ¤ ì½”ë“œë¥¼ datasetì— ë§ë„ë¡ ìë™ ì½”ë“œí™” í•©ë‹ˆë‹¤. ì½”ë“œ ìƒì„± ë°˜ë³µ íšŸìˆ˜ë¥¼ ì„ íƒí•  ìˆ˜ ìˆë‹ˆë‹¤.   \n   1íšŒ ì‹¤í–‰ ì‹œì— 2~3ë¶„ ì •ë„ ì†Œìš”ë˜ë©°, iterationë³´ë‹¤ ì¼ì° ì„±ê³µí•œ ê²½ìš° ìë™ ì¢…ë£Œë˜ë¯€ë¡œ 10íšŒ ì„¤ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.')
        
        # cols = st.columns([1, 1])
        # with cols[0]:
        #     st.session_state['max_iterations_data'] = st.number_input("iteration", 1, 20, value=st.session_state['max_iterations_data'], step=1, key="code_gen_iteration", help="ìƒì„±í˜• AI ê¸°ë°˜ìœ¼ë¡œ code ì œì‘ ì‹œ, ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì˜ë¯¸ í•©ë‹ˆë‹¤.")
        # with cols[1]:
        #     st.text("")  # ê³µë°± ì¶”ê°€
        #     btn_create = st.button("Create", use_container_width=True, )
        st.text("")  # ê³µë°± ì¶”ê°€
        btn_create = st.button("Create", use_container_width=True, )
        return btn_create
    
    def check_progress(self, btn_create):
        st.write('#### Check Progress')
        st.caption('ì§„í–‰ ìƒí™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ì´ë‚˜ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì§„í–‰ì´ ë©ˆì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.')

        if st.session_state["log_data"] and not st.session_state["is_btn_clicked_data"]:
            st.markdown(st.session_state["log_data"], unsafe_allow_html=True)

        if btn_create:
            st.session_state["is_btn_clicked_data"] = True
            st.session_state["placeholder_data"] = st.empty()
            st.session_state["log_data"] = ""
            st.session_state["data_adapt"] = None

    def _get_log(self, log):
        st.session_state["log_data"] += log
        st.markdown(log, unsafe_allow_html=True)

    def check_source_code(self):
        log = ""
        file_name = None

        if os.path.exists(self.py_path):
            py_files = [f for f in os.listdir(self.py_path) if f.endswith('.py')]
            file_name = py_files[0]
            log = f"python ({file_name}) íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤. code ë³€í™˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n"
        else:
            log = "ì†ŒìŠ¤ ì½”ë“œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
        
        return [file_name, log]

    def read_metadata_from_markdown(self, file_path):
        metadata = {}
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as md_file:
                current_section = None
                for line in md_file:
                    line = line.strip()
                    if line.startswith("- **") and line.endswith("**:"):
                        current_section = line[4:-3]
                        metadata[current_section] = {}
                    elif line.startswith("  - **") and line.endswith("**:"):
                        if current_section is not None:
                            sub_section = line[6:-3]
                            sub_value = line.split("**: ")[1]
                            metadata[current_section][sub_section] = sub_value
                    elif current_section and line:
                        if "description:" in current_section:
                            metadata[current_section] = line  # ì „ì²´ ë‚´ìš©ìœ¼ë¡œ ê°±ì‹ 
        return metadata

    def parse_md_to_dict(self, md_file_path):
        with open(md_file_path, 'r') as file:
            content = file.read()

        # Define a regex pattern to match the key-value pairs
        pattern = r'- \*\*(.*?)\*\*:\s*(\{.*?\})'

        # Find all matches in the content
        matches = re.findall(pattern, content, re.DOTALL)

        result_dict = {}
        for key, value in matches:
            clean_key = key.strip()
            clean_value = value.strip()

            # Attempt to convert clean_value to a valid JSON format if necessary
            if clean_key in ['data_path', 'data_hierarchy']:
                try:
                    result_dict[clean_key] = json.loads(clean_value.replace("'", "\""))
                except json.JSONDecodeError as e:
                    print(f"JSON decode error for key '{clean_key}': {e}")
                    print(f"Original value: {clean_value}")
            else:
                result_dict[clean_key + ':'] = clean_value

        return result_dict

    def generate_code(self):

        def read_py_files(folder_path):
            py_files_content = {}

            for filename in os.listdir(folder_path):
                if filename.endswith('.py'):
                    file_path = os.path.join(folder_path, filename)
                    with open(file_path, 'r', encoding='utf-8') as file:
                        file_content = file.read()
                        py_files_content['generation_py'] = file_content

                if filename.endswith('requirements.txt'):
                    file_path = os.path.join(folder_path, filename)
                    with open(file_path, 'r', encoding='utf-8') as file:
                        file_content = file.read()
                        py_files_content['generation_req'] = file_content

            return py_files_content

        
        
        def format_table_as_string(data):
            """
            ì£¼ì–´ì§„ ì´ì°¨ì› ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë¬¸ìì—´ ë°˜í™˜.

            Args:
            data (list of list of str): í…Œì´ë¸”ë¡œ ë³€í™˜í•  ë¬¸ìì—´ ì´ì°¨ì› ë¦¬ìŠ¤íŠ¸.

            Returns:
            str: í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜ëœ ë¬¸ìì—´.
            """
            # í—¤ë”ì™€ êµ¬ë¶„ì„ 
            separator = "-" * 50 + "\n"

            # ë°ì´í„° í–‰ ìƒì„±
            rows = [separator]
            for idx, item in enumerate(data, start=1):
                row = f"{idx:<5}. || {item[0]:<15} || {item[1]} \n"
                rows.append(row)

            # í…Œì´ë¸” ë¬¸ìì—´ ê²°í•©
            table_string = separator + ''.join(rows)

            return table_string

        self._get_log("<p style='color:blue; font-weight:bold;'>ğŸš— Processing...</p>")
        file_name, log = self.check_source_code()
        py_path = os.path.join(self.py_path, file_name)
        req_path = os.path.join(self.py_path, 'requirements.txt')
        self._get_log(log)

        with open(DATA_META_PATH + 'data_meta.json', 'r', encoding='utf-8') as json_file:
            metadata = json.load(json_file)

        runner_input_dict = read_py_files(self.py_path)
        metadata2 = {'data_meta':metadata}
        runner_input_dict.update(metadata2)

        st.session_state['data_adapt'] = GraphRunner(
            prev_step_result_dict=runner_input_dict,
            py_path = py_path,
            req_path = req_path
        )

        # st.session_state['data_adapt'] = DataAdapt(
        #     py_path,
        #     req_path,
        #     data_meta_path= os.path.join(self.data_path, 'description.txt'),
        #     max_iterations=st.session_state.max_iterations)
        #     #generation_mode= 'data_adaptation')
        try:
            
            with st.spinner('Code generator running...'):
                result = st.session_state['data_adapt'].run()
            #     for i in range(10):
            #         print(result)   
            
            if isinstance(result, dict):
                self._get_log("<p style='color:blue; font-weight:bold;'>ğŸš© End</p>")
                error_log_list = []
                error_log = result['log_lst']
                for i in range(len(error_log)):
                    error_log_prompt = f"""
                    ì•„ë˜ì— ì…ë ¥ë°›ëŠ” ë”•ì…”ë„ˆë¦¬ëŠ” ì½”ë“œì˜ ì˜¤ë¥˜ì— ëŒ€í•œ logì•¼. ë„ˆëŠ” ì—ëŸ¬ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ê°„ë‹¨í•˜ê²Œ ìš”ì•½í•´ì£¼ëŠ” ì‹œìŠ¤í…œì´ì•¼.
                    ë„ˆì˜ ì¶œë ¥ì„ tableì˜ descriptionì— ë“¤ì–´ê°ˆê±°ì•¼.
                    ```
                    {error_log[i]['error_raw']}
                    ```
                    ì¶œë ¥ì€ ì£¼ìš” ì—ëŸ¬ ë¡œê·¸ í•œ ì¤„ê³¼ ë°œìƒí•œ ì›ì¸ì„ í•œì¤„ë¡œ ì•„ë˜ì˜ í˜•íƒœë¥¼ ìœ ì§€í•´ì¤˜.
                    ex) ModuleNotFoundError:, ëª¨ë“ˆì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
                    """
                    try:
                        error_log_response = chatgpt_query(error_log_prompt)
                    except Exception as e:
                        st.error(f"ChatGPT API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
                        return None
                    #error_log_list += [f"No. {i+1} || {error_log[i]['error_type']} || {error_log_response} \n"]
                    error_log_list.append({
                        "Error Type": error_log[i]['error_type'],
                        "Description": error_log_response
                    })
                df = pd.DataFrame(error_log_list)
                st.write("**Error Type Description**")
                st.write("type_1, 2: code error")
                st.write("type_3: library error")
                st.write("type_4: envirments error")
                st.write("**Inprogress history**")
                st.table(df)
                if 'success' in result['graph_result'].lower():
                    self._get_log("â­• Data Adaptaion ì„±ê³µ !!\n")
                    # ë³µì‚¬ VENV_PATH ì—¬ê¸°ì„œ ë³µì‚¬
                    source_file_path = os.path.join(VENV_PATH, 'requirements.txt')
                    # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                    if os.path.exists(source_file_path):
                        # B í´ë”ì— ë³µì‚¬í•  íŒŒì¼ì˜ ê²½ë¡œ
                        destination_file_path = os.path.join(SOURCE_PY_PATH, 'requirements.txt')
                        shutil.copy(source_file_path, destination_file_path)
                        print(f"requirements.txt íŒŒì¼ì„ {VENV_PATH}ì—ì„œ {SOURCE_PY_PATH}ë¡œ ë³µì‚¬í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        print(f"requirements.txt íŒŒì¼ì´ {VENV_PATH}ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    last_error = result['last_error']
                    #ì§€í”¼í‹°ì— ëŒ€í•œ ì§ˆë¬¸ ì¶”ê°€
                    error_report_prompt = f"""
                    ì•„ë˜ì— ì…ë ¥ë°›ëŠ” ë”•ì…”ë„ˆë¦¬ëŠ” ì½”ë“œì˜ ì˜¤ë¥˜ì— ëŒ€í•œ logì•¼. ë„ˆëŠ” ì—ëŸ¬ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ì‚¬ìš©ìì—ê²Œ ì–´ë–»ê²Œ ìˆ˜ì •í•´ì•¼ë˜ëŠ”ì§€ ì•Œë ¤ì£¼ëŠ” ì‹œìŠ¤í…œì´ì•¼.
                    ```
                    {last_error}
                    ```
                    ì£¼ìš”í•œ ì—ëŸ¬ ë¡œê·¸ì™€ ì–´ë–»ê²Œ ìˆ˜ì •í•´ì•¼ë˜ëŠ”ì§€ ë“±ì˜ ê°€ì´ë“œë¼ì¸ì„ ë¦¬í¬íŠ¸ í˜•íƒœë¡œ ë‹µë³€í•´ì¤˜.
                    ì„¤ëª…ì€ í•œê¸€ë¡œ ë¶€íƒí•´.
                    ì œì¼ í° ê¸€ì”¨ëŠ” ì œëª©ì€ **ë¡œ ë‚´ìš©ì€ ê·¸ê±°ë³´ë‹¤ ì‘ê²Œ ì¨ì£¼ê³ , ë‚´ìš©ì€ ì˜¤ë¥˜ ë©”ì‹œì§€(ì£¼ìš” ë‚´ìš© í¬í•¨), ì›ì¸, ìˆ˜ì •ë°©ë²•ë§Œ ì§§ê²Œ ì ì–´ì¤˜.
                    """
                    try:
                        response = chatgpt_query(error_report_prompt)
                    except Exception as e:
                        st.error(f"ChatGPT API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
                        return None
                        #error_log_table = format_table_as_string(error_log_list)
                    self._get_log(f"âŒ Data Adaptaion ì‹¤íŒ¨í•¨. Artifact files ì—ì„œ Error log ë¥¼ í™•ì¸ í•˜ì„¸ìš”.\n")
                    self._get_log(f" {response} \n")

            else:
                pass
            # st.text(f"{file_name} ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            with st.expander(f"âŒ {file_name} ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"):
                self._get_log(f"{e}\n")
        st.session_state['progress_data'] = "end"
    
    def render(self):
        st.write('### Adapt code for dataset with AI Agent')
        self.show_adapt_code_info()
        is_checked = False 
        try: 
            is_checked = self.check_condition() 
        except: 
            st.error("ì†ŒìŠ¤ì½”ë“œ í˜¹ì€ ë°ì´í„°ì…‹ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if is_checked:
            directory_structure = self.print_directory_tree(self.data_path)
            btn_create = self.create_solution()

            st.divider()
            self.check_progress(btn_create)

            if st.session_state["placeholder_data"] and st.session_state["is_btn_clicked_data"]:
                st.session_state["is_btn_clicked_data"] = False
                with st.session_state["placeholder_data"].container():
                    # self.init_solution()
                    self.generate_code()
        else: 
            pass 